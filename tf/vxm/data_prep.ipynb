{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "# local imports\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, activations, initializers, regularizers, optimizers, losses, callbacks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from IPython import display \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "from ants import from_numpy, resample_image, registration, apply_transforms\n",
    "import pydicom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Moving_phase = 'A'\n",
    "fixed_phase  = 'D'\n",
    "patch_size = 64\n",
    "\n",
    "\n",
    "train_A = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_a2d/input/train/example_A\"\n",
    "train_D = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_a2d/input/train/example_B\"\n",
    "val_A = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_a2d/input/val/example_A\"\n",
    "val_D = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_a2d/input/val/example_B\"\n",
    "\n",
    "train_A_paths = [os.path.join(train_A, folder) for folder in os.listdir(train_A)]\n",
    "train_D_paths = [os.path.join(train_D, folder) for folder in os.listdir(train_D)]\n",
    "val_A_paths = [os.path.join(val_A, folder) for folder in os.listdir(val_A)]\n",
    "val_D_paths = [os.path.join(val_D, folder) for folder in os.listdir(val_D)]\n",
    "\n",
    "\n",
    "train_A_paths.sort()\n",
    "train_D_paths.sort()\n",
    "val_A_paths.sort()\n",
    "val_D_paths.sort()\n",
    "\n",
    "#\n",
    "Train_num  = len(train_A_paths)\n",
    "Val_num = len(val_A_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_dicom_files(dicom_dir):\n",
    "    try:\n",
    "        dicom_files = glob.glob(os.path.join(dicom_dir, \"*.*\"))\n",
    "        sorted_dicom_files = sorted(dicom_files)\n",
    "        stacked_dicom = [pydicom.dcmread(dicom_file) for dicom_file in sorted_dicom_files]\n",
    "        return stacked_dicom\n",
    "    except IndexError as e:\n",
    "        print(f\"{e}, at path {dicom_dir}\")\n",
    "        return None\n",
    "\n",
    "def create_3d(dicom_files):\n",
    "    stacked_dicom = dicom_files  # stack of dicom files in a list\n",
    "\n",
    "    image_shape = list(stacked_dicom[0].pixel_array.shape)\n",
    "    image_shape.append(len(stacked_dicom))\n",
    "    image_3d = np.zeros(image_shape)\n",
    "\n",
    "    for j in range(len(stacked_dicom)):\n",
    "        image_3d[:, :, j] = stacked_dicom[j].pixel_array\n",
    "\n",
    "    return image_3d\n",
    "\n",
    "def make_patches(image, patch_size= 64):\n",
    "    stride = int(patch_size)\n",
    "\n",
    "    image_patches = []\n",
    "    locations = []\n",
    "    for i in range(0, image.shape[0], stride):\n",
    "        for j in range(0, image.shape[1], stride):\n",
    "            Patch = np.zeros((patch_size,patch_size,192))\n",
    "            Patch[Patch==0]= -1024/10000\n",
    "            img_patch = image[i:i + patch_size,j:j + patch_size, :]\n",
    " \n",
    "            Patch[: img_patch.shape[0],:img_patch.shape[1],:] = img_patch\n",
    "\n",
    "            patch_img = Patch\n",
    "            image_patches.append(patch_img)\n",
    "            locations.append((i, j))\n",
    "\n",
    "    patch_array = np.zeros((len(image_patches),patch_size,patch_size,image.shape[-1]))\n",
    "    # print(\"len img patch\", len(image_patches))\n",
    "    \n",
    "    for idx in range(len(image_patches)):\n",
    "        patch_array[idx,:,:,:] =image_patches[idx]\n",
    "    return patch_array, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: './patch_data_A_D_64'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▋                                                          | 172/634 [1:38:29<4:53:40, 38.14s/it]/home/monib/Downloads/d/envs/vm2/lib/python3.8/site-packages/pydicom/charset.py:746: UserWarning:\n",
      "\n",
      "Unknown encoding 'ISO IR 149' - using default encoding instead\n",
      "\n",
      " 62%|█████████████████████████████████████████████████▍                              | 392/634 [3:47:41<2:04:48, 30.94s/it]/home/monib/Downloads/d/envs/vm2/lib/python3.8/site-packages/pydicom/charset.py:754: UserWarning:\n",
      "\n",
      "Unknown encoding 'ISO_IR 149' - using default encoding instead\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 634/634 [5:30:25<00:00, 31.27s/it]\n"
     ]
    }
   ],
   "source": [
    "T_moving = np.zeros((512,512,192))\n",
    "T_fixed  = np.zeros((512,512,192))\n",
    "\n",
    "# for i in tqdm(range(Train_num)):\n",
    "#     moving = create_3d(read_dicom_files(train_P_paths[i]))/10000\n",
    "#     fixed = create_3d(read_dicom_files(train_A_paths[i]))/10000\n",
    "#     T_moving[...,:moving.shape[-1]] = moving\n",
    "#     T_fixed[...,:fixed.shape[-1]] = fixed\n",
    "#\n",
    "# # print(\"Training Moving Data info\")\n",
    "# # print(T_moving.shape)\n",
    "# # print(T_moving.min())\n",
    "# # print(T_moving.max())\n",
    "# #\n",
    "# # print(\"Training Fixed Data info\")\n",
    "# # print(T_fixed.shape)\n",
    "# # print(T_fixed.min())\n",
    "# # print(T_fixed.max())\n",
    "#\n",
    "#\n",
    "# V_moving = np.zeros((512,512,192))\n",
    "# V_fixed  = np.zeros((512,512,192))\n",
    "#\n",
    "# for i in tqdm(range(Val_num)):\n",
    "#     moving = create_3d(read_dicom_files(val_P_paths[i]))/10000\n",
    "#     fixed = create_3d(read_dicom_files(val_A_paths[i]))/10000\n",
    "#     V_moving[...,:moving.shape[-1]] = moving\n",
    "#     V_fixed[...,:fixed.shape[-1]] = fixed\n",
    "\n",
    "# print(\"Val Moving Data info\")\n",
    "# print(V_moving.shape)\n",
    "# print(V_moving.min())\n",
    "# print(V_moving.max())\n",
    "#\n",
    "# print(\"Val Fixed Data info\")\n",
    "# print(V_fixed.shape)\n",
    "# print(V_fixed.min())\n",
    "# print(V_fixed.max())\n",
    "\n",
    "patch_save_path = f'./patch_data_{Moving_phase}_{fixed_phase}_{patch_size}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(patch_save_path)\n",
    "except FileExistsError as err:\n",
    "    print(err)\n",
    "else:\n",
    "    print(patch_save_path)\n",
    "\n",
    "patch_number = int((512/patch_size)*(512/patch_size))\n",
    "\n",
    "for i in tqdm(range(Train_num)):\n",
    "    # TODO: create single image and save it as an array of patches\n",
    "    moving = create_3d(read_dicom_files(train_A_paths[i]))/10000\n",
    "    fixed = create_3d(read_dicom_files(train_D_paths[i]))/10000\n",
    "    if moving.shape[-1] < 192:\n",
    "        \n",
    "        T_moving[...,:moving.shape[-1]] = moving\n",
    "        T_fixed[...,:fixed.shape[-1]] = fixed\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "        \n",
    "    moving_patches , _ = make_patches(T_moving,patch_size)\n",
    "    fixed_patches  , _ = make_patches(T_fixed,patch_size)\n",
    "\n",
    "    for j in range(patch_number):\n",
    "        moving = moving_patches[j:j+1]\n",
    "        fixed = fixed_patches[j:j+1]\n",
    "        np.savez(f'{patch_save_path}/{i*patch_number+j}.npz',moving=moving,fixed=fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}