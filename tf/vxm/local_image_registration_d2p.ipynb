{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7847f5-9d82-4fe3-94e1-05a98bf34469",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code Flow\n",
    "\n",
    "### 1. Data preprocessing \n",
    "    * Voxel Morph model input을 맞추기 위한 과정\n",
    "\n",
    "### 2. Voxel Morph Model build\n",
    "\n",
    "### 3. Train\n",
    "\n",
    "### 4. Inference step\n",
    "    * Patch image reconstuction Step\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fd114-e966-4cdd-b081-9af4d6b7abe2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83567e20-35eb-4050-93e9-1f76c000d0c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 15:49:49.416007: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "# local imports\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, activations, initializers, regularizers, optimizers, losses, callbacks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from IPython import display \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "from ants import from_numpy, resample_image, registration, apply_transforms\n",
    "import pydicom\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.set_visible_devices(gpus[1], 'GPU') # using GPU1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4cc9f-6a83-48ba-8b5a-d4ef880985a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "# Variable & Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a2b805-0bec-42d0-bb44-ede20016d333",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Moving_phase = 'D'\n",
    "fixed_phase  = 'P'\n",
    "patch_size = 64\n",
    "\n",
    "\n",
    "train_D = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_d2p/train/example_A\"\n",
    "train_P = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_d2p/train/example_B\"\n",
    "val_D = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_d2p/val/example_A\"\n",
    "val_P = \"/media/monib/ext1/work2022/Base_Dataset/vm_data_affine_d2p/val/example_B\"\n",
    "\n",
    "train_D_paths = [os.path.join(train_D, folder) for folder in os.listdir(train_D)]\n",
    "train_P_paths = [os.path.join(train_P, folder) for folder in os.listdir(train_P)]\n",
    "val_D_paths = [os.path.join(val_D, folder) for folder in os.listdir(val_D)]\n",
    "val_P_paths = [os.path.join(val_P, folder) for folder in os.listdir(val_P)]\n",
    "\n",
    "\n",
    "train_D_paths.sort()\n",
    "train_P_paths.sort()\n",
    "val_D_paths.sort()\n",
    "val_P_paths.sort()\n",
    "\n",
    "#\n",
    "Train_num  = len(train_D_paths)\n",
    "Val_num = len(val_D_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e2f00-9f27-455c-affe-bf442bffb031",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Utils function & Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca1c76c-c11f-49d4-b581-58ea929980ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# Result Analysis function #\n",
    "############################\n",
    "\n",
    "def get_2d_quiver(flow_2d, sp_factor = 20):\n",
    "    \"\"\"\n",
    "    flow_2d: Flow filed in 2d+3 format. Example (512,512,3)\n",
    "    sp_factor = sparsity factor.\n",
    "    \"\"\"\n",
    "    spatial_flow = flow_2d[:, :, 0:2]\n",
    "    meshg = meshgridnd_like(spatial_flow[::sp_factor, ::sp_factor, 0])\n",
    "    mesh = np.asarray(meshg)\n",
    "    mesh_mv = np.moveaxis(mesh, 0, -1)\n",
    "    meshX = mesh_mv[:, :, 0]\n",
    "    meshY = mesh_mv[:, :, 1]\n",
    "\n",
    "\n",
    "    flowX_2d = flow_2d[::sp_factor, ::sp_factor, 0]\n",
    "    flowY_2d = flow_2d[::sp_factor, ::sp_factor, 1]\n",
    "    flowZ_2d = flow_2d[::sp_factor, ::sp_factor, 2]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "    ax.quiver(meshX, meshY, flowX_2d, flowY_2d, flowZ_2d )\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def meshgridnd_like(in_img, rng_func=range):\n",
    "    new_shape = list(in_img.shape)\n",
    "    all_range = [rng_func(i_len) for i_len in new_shape]\n",
    "    return tuple([x_arr.swapaxes(0, 1) for x_arr in np.meshgrid(*all_range)])\n",
    "def norm (array):\n",
    "    array = (array-array.min())/(array.max() - array.min())\n",
    "    return array\n",
    "\n",
    "\n",
    "#######################\n",
    "## Callback function ##\n",
    "#######################\n",
    "\n",
    "def plot_history(hist, loss_name='loss'):\n",
    "    # Simple function to plot training history.\n",
    "    plt.figure()\n",
    "    plt.plot(hist.epoch, hist.history[loss_name], '-')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_curve(log_df,\n",
    "                        loss_name='loss',\n",
    "                        loo_idx=None,\n",
    "                        ylim=(None, None),\n",
    "                        logscale=False,\n",
    "                        **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Data from the log.csv\n",
    "    epochs = np.arange(log_df.epoch.iloc[0] + 1, log_df.epoch.iloc[-1] + 2, 1, dtype=np.uint32)\n",
    "\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.figure(figsize=kwargs.get('fig_size', (9, 5)))\n",
    "\n",
    "    if loo_idx is not None:\n",
    "        plt.title(f'Learning Curves (Loss) (LOOCV: {loo_idx + 1})')\n",
    "    else:\n",
    "        plt.title(f'Learning Curves ({loss_name})')\n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.ylabel('Loss')\n",
    "    if logscale:\n",
    "        plt.yscale('log')\n",
    "        plt.grid(True, which='both')\n",
    "    if ylim[0] is not None:\n",
    "        plt.ylim(bottom=ylim[0])\n",
    "    if ylim[1] is not None:\n",
    "        plt.ylim(top=ylim[1])\n",
    "    plt.plot(epochs, log_df[f'{loss_name}'], '-', label='Training')\n",
    "    # plt.plot(epochs, log_df[f'val_{loss_name}'], '-', label='Validation')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.style.use('seaborn-white')\n",
    "    \n",
    "def read_dicom_files(dicom_dir):\n",
    "    try:\n",
    "        dicom_files = glob.glob(os.path.join(dicom_dir, \"*.*\"))\n",
    "        sorted_dicom_files = sorted(dicom_files)\n",
    "        stacked_dicom = [pydicom.dcmread(dicom_file) for dicom_file in sorted_dicom_files]\n",
    "        return stacked_dicom\n",
    "    except IndexError as e:\n",
    "        print(f\"{e}, at path {dicom_dir}\")\n",
    "        return None\n",
    "\n",
    "def create_3d(dicom_files):\n",
    "    stacked_dicom = dicom_files  # stack of dicom files in a list\n",
    "\n",
    "    image_shape = list(stacked_dicom[0].pixel_array.shape)\n",
    "    image_shape.append(len(stacked_dicom))\n",
    "    image_3d = np.zeros(image_shape)\n",
    "\n",
    "    for j in range(len(stacked_dicom)):\n",
    "        image_3d[:, :, j] = stacked_dicom[j].pixel_array\n",
    "\n",
    "    return image_3d\n",
    "\n",
    "def make_patches(image,patch_size= 64):\n",
    "    stride = int(patch_size)\n",
    "\n",
    "    image_patches = []\n",
    "    locations = []\n",
    "    for i in range(0, image.shape[0], stride):\n",
    "        for j in range(0, image.shape[1], stride):\n",
    "            Patch = np.zeros((patch_size,patch_size,192))\n",
    "            Patch[Patch==0]= -1024/10000\n",
    "            img_patch = image[i:i + patch_size,j:j + patch_size, :]\n",
    "\n",
    "            Patch[: img_patch.shape[0],:img_patch.shape[1],:] = img_patch\n",
    "\n",
    "            patch_img = Patch\n",
    "            image_patches.append(patch_img)\n",
    "            locations.append((i, j))\n",
    "\n",
    "    patch_array = np.zeros((len(image_patches),patch_size,patch_size,image.shape[-1]))\n",
    "    for idx in range(len(image_patches)):\n",
    "        patch_array[idx,:,:,:] =image_patches[idx]\n",
    "    return patch_array, locations\n",
    "\n",
    "\n",
    "class LearningCurveCallback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        log_df = pd.read_csv(os.path.join(save_model_path, r'log_d2p.csv'))\n",
    "        display.display(log_df[-20:])\n",
    "        plot_learning_curve(log_df, loss_name = 'vxm_dense_flow_loss')\n",
    "        plot_learning_curve(log_df, loss_name = 'vxm_dense_transformer_loss')\n",
    "        plot_learning_curve(log_df,loss_name='loss')\n",
    "        \n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedbae4-b2c9-4b34-b6b2-fcb4b513239f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# 1. Data Load & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf224feb-6f2f-4ec3-8247-8dc95008b4fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train_num = 4\n",
    "# Val_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7e070d-6e16-4bdb-b17b-b8800b305cf7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "T_moving = np.zeros((512,512,192))\n",
    "T_fixed  = np.zeros((512,512,192))\n",
    "\n",
    "# for i in tqdm(range(Train_num)):\n",
    "#     moving = create_3d(read_dicom_files(train_P_paths[i]))/10000\n",
    "#     fixed = create_3d(read_dicom_files(train_A_paths[i]))/10000\n",
    "#     T_moving[...,:moving.shape[-1]] = moving\n",
    "#     T_fixed[...,:fixed.shape[-1]] = fixed\n",
    "#\n",
    "# # print(\"Training Moving Data info\")\n",
    "# # print(T_moving.shape)\n",
    "# # print(T_moving.min())\n",
    "# # print(T_moving.max())\n",
    "# #\n",
    "# # print(\"Training Fixed Data info\")\n",
    "# # print(T_fixed.shape)\n",
    "# # print(T_fixed.min())\n",
    "# # print(T_fixed.max())\n",
    "#\n",
    "#\n",
    "# V_moving = np.zeros((512,512,192))\n",
    "# V_fixed  = np.zeros((512,512,192))\n",
    "#\n",
    "# for i in tqdm(range(Val_num)):\n",
    "#     moving = create_3d(read_dicom_files(val_P_paths[i]))/10000\n",
    "#     fixed = create_3d(read_dicom_files(val_A_paths[i]))/10000\n",
    "#     V_moving[...,:moving.shape[-1]] = moving\n",
    "#     V_fixed[...,:fixed.shape[-1]] = fixed\n",
    "\n",
    "# print(\"Val Moving Data info\")\n",
    "# print(V_moving.shape)\n",
    "# print(V_moving.min())\n",
    "# print(V_moving.max())\n",
    "#\n",
    "# print(\"Val Fixed Data info\")\n",
    "# print(V_fixed.shape)\n",
    "# print(V_fixed.min())\n",
    "# print(V_fixed.max())\n",
    "\n",
    "# patch_save_path = f'./patch_data_{Moving_phase}_{fixed_phase}_{patch_size}'\n",
    "\n",
    "# try:\n",
    "#     os.makedirs(patch_save_path)\n",
    "# except FileExistsError as err:\n",
    "#     print(err)\n",
    "# else:\n",
    "#     print(patch_save_path)\n",
    "\n",
    "\"\"\"\n",
    "FIXME: Double check this part\n",
    "\"\"\"\n",
    "patch_number = int((512/patch_size)*(512/patch_size))\n",
    "\n",
    "# for i in tqdm(range(Train_num)):\n",
    "#     # TODO: create single image and save it as an array of patches\n",
    "#     moving = create_3d(read_dicom_files(train_D_paths[i]))/10000\n",
    "#     fixed = create_3d(read_dicom_files(train_P_paths[i]))/10000\n",
    "#     if moving.shape[-1] < 192:\n",
    "#         T_moving[...,:moving.shape[-1]] = moving\n",
    "#         T_fixed[...,:fixed.shape[-1]] = fixed\n",
    "#     else: \n",
    "#         continue\n",
    "\n",
    "#     moving_patches , _ = make_patches(T_moving,patch_size)\n",
    "#     fixed_patches  , _ = make_patches(T_fixed,patch_size)\n",
    "\n",
    "#     for j in range(patch_number):\n",
    "#         moving = moving_patches[j:j+1]\n",
    "#         fixed = fixed_patches[j:j+1]\n",
    "#         np.savez(f'{patch_save_path}/{i*patch_number+j}.npz',moving=moving,fixed=fixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00be5f5-be2e-4ffe-82b4-3e4a1c466c7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "# 2. Voxel Morph Model build & Compile \n",
    "\n",
    "* Use losses : Ncc loss(1), Gradient loss(0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf27744-701a-46ba-b300-3fe05ccba3df",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 15:50:17.869462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-21 15:50:18.388254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22304 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 64, 64, 192, 1) dtype=float32 (created by layer 'vxm_dense_source_input')>, <KerasTensor: shape=(None, 64, 64, 192, 1) dtype=float32 (created by layer 'vxm_dense_target_input')>]\n",
      "[<KerasTensor: shape=(None, 64, 64, 192, 1) dtype=float32 (created by layer 'vxm_dense_transformer')>, <KerasTensor: shape=(None, 64, 64, 192, 3) dtype=float32 (created by layer 'vxm_dense_flow')>]\n"
     ]
    }
   ],
   "source": [
    "vol_shape = (64, 64, 192)\n",
    "nb_features = [\n",
    "    [16, 32, 32, 32],\n",
    "    [32, 32, 32, 32, 32, 16, 16]\n",
    "]\n",
    "\n",
    "vxm_model = vxm.networks.VxmDense(vol_shape, nb_features, int_steps=0)\n",
    "\n",
    "print(vxm_model.input)\n",
    "print(vxm_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cb01b3-6f83-436a-a681-aecde54e0db2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Callback & weight save path\n",
    "save_model_path = f'./model_d2p' \n",
    "checkpointer = callbacks.ModelCheckpoint(os.path.join(f'{save_model_path}','weights_{epoch:05d}_{loss:.4g}.h5'),save_weights_only=True)\n",
    "csv_logger = callbacks.CSVLogger(f'{save_model_path}/log_d2p.csv', append=True)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='loss', patience=40)\n",
    "plot_learning_curves_epoch = LearningCurveCallback()\n",
    "\n",
    "# Loss\n",
    "losses = [vxm.losses.NCC().loss, vxm.losses.Grad('l2').loss]\n",
    "lambda_param = 0.01\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ae670-74d0-4be2-8936-e728c61d4375",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# With batch size\n",
    "# def vxm_data_generator(data_number = 75*64, batch_size=128, input_shape = (64,64,192)):\n",
    "    \n",
    "#     moving_images = np.zeros([batch_size, *input_shape])\n",
    "#     fixed_images = np.zeros([batch_size, *input_shape])\n",
    "#     zero_phi = np.zeros([batch_size,*input_shape])\n",
    "#     print(\"zero moving shape\", moving_images.shape)\n",
    "#     while True:\n",
    "        \n",
    "#         idx1 = np.random.randint(0, data_number, size=batch_size)\n",
    "#         for i in range(len(idx1)):\n",
    "#             data = np.load(f'/media/monib/ext1/work2022/Base_Dataset/affined_patch_data/patch_data_{Moving_phase}_{fixed_phase}_{patch_size}/{idx1[i]}.npz')\n",
    "\n",
    "#             moving_image = data['moving']\n",
    "#             fixed_image  = data['fixed']\n",
    "            \n",
    "#             moving_images[i][:, :, :] = moving_image\n",
    "#             fixed_images[i][:, :, :] = fixed_image\n",
    "            \n",
    "#         inputs = [moving_images, fixed_images]\n",
    "\n",
    "#         outputs = [fixed_images, zero_phi]\n",
    "\n",
    "#         yield inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b49b2bb1-fdc4-4bf0-a097-2eb8b8d08202",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vxm_data_generator(data_number = 75*64, batch_size=128):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        idx1 = np.random.randint(0, data_number, size=batch_size)\n",
    "\n",
    "        data = np.load(f'/media/monib/ext1/work2022/Base_Dataset/affined_patch_data/patch_data_{Moving_phase}_{fixed_phase}_{patch_size}/{idx1[0]}.npz')\n",
    "\n",
    "        moving_images = data['moving']\n",
    "        fixed_images  = data['fixed']\n",
    "\n",
    "        zero_phi = np.zeros([batch_size,*fixed_images.shape[1:4]])\n",
    "\n",
    "\n",
    "        inputs = [moving_images, fixed_images]\n",
    "\n",
    "        outputs = [fixed_images, zero_phi]\n",
    "\n",
    "        yield inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3095db42-92d9-4425-b8ee-538229bef9d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = vxm_data_generator(Train_num,patch_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd5499-8e06-44c8-a0ca-4091cdbea928",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>vxm_dense_flow_loss</th>\n",
       "      <th>vxm_dense_transformer_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>-0.988962</td>\n",
       "      <td>0.131812</td>\n",
       "      <td>-0.990279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>-0.988961</td>\n",
       "      <td>0.131451</td>\n",
       "      <td>-0.990274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>-0.988831</td>\n",
       "      <td>0.130910</td>\n",
       "      <td>-0.990137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>-0.988862</td>\n",
       "      <td>0.130592</td>\n",
       "      <td>-0.990163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>-0.989018</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>-0.990306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>-0.989153</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>-0.990417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>-0.988746</td>\n",
       "      <td>0.131354</td>\n",
       "      <td>-0.990062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>-0.989231</td>\n",
       "      <td>0.125961</td>\n",
       "      <td>-0.990485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.988893</td>\n",
       "      <td>0.131827</td>\n",
       "      <td>-0.990214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>-0.988845</td>\n",
       "      <td>0.131758</td>\n",
       "      <td>-0.990158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.988959</td>\n",
       "      <td>0.130955</td>\n",
       "      <td>-0.990273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>-0.989034</td>\n",
       "      <td>0.128448</td>\n",
       "      <td>-0.990315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>-0.988970</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>-0.990308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>-0.989023</td>\n",
       "      <td>0.129902</td>\n",
       "      <td>-0.990314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>-0.989030</td>\n",
       "      <td>0.130440</td>\n",
       "      <td>-0.990330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>-0.989055</td>\n",
       "      <td>0.130347</td>\n",
       "      <td>-0.990354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>-0.988940</td>\n",
       "      <td>0.131327</td>\n",
       "      <td>-0.990249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>-0.989008</td>\n",
       "      <td>0.131465</td>\n",
       "      <td>-0.990321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>-0.988995</td>\n",
       "      <td>0.131758</td>\n",
       "      <td>-0.990310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>-0.989246</td>\n",
       "      <td>0.132322</td>\n",
       "      <td>-0.990564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss  vxm_dense_flow_loss  vxm_dense_transformer_loss\n",
       "78     78 -0.988962             0.131812                   -0.990279\n",
       "79     79 -0.988961             0.131451                   -0.990274\n",
       "80     80 -0.988831             0.130910                   -0.990137\n",
       "81     81 -0.988862             0.130592                   -0.990163\n",
       "82     82 -0.989018             0.128676                   -0.990306\n",
       "83     83 -0.989153             0.127022                   -0.990417\n",
       "84     84 -0.988746             0.131354                   -0.990062\n",
       "85     85 -0.989231             0.125961                   -0.990485\n",
       "86     86 -0.988893             0.131827                   -0.990214\n",
       "87     87 -0.988845             0.131758                   -0.990158\n",
       "88     88 -0.988959             0.130955                   -0.990273\n",
       "89     89 -0.989034             0.128448                   -0.990315\n",
       "90     90 -0.988970             0.133700                   -0.990308\n",
       "91     91 -0.989023             0.129902                   -0.990314\n",
       "92     92 -0.989030             0.130440                   -0.990330\n",
       "93     93 -0.989055             0.130347                   -0.990354\n",
       "94     94 -0.988940             0.131327                   -0.990249\n",
       "95     95 -0.989008             0.131465                   -0.990321\n",
       "96     96 -0.988995             0.131758                   -0.990310\n",
       "97     97 -0.989246             0.132322                   -0.990564"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12015/36352 [========>.....................] - ETA: 53:54 - loss: -0.9889 - vxm_dense_transformer_loss: -0.9902 - vxm_dense_flow_loss: 0.1346"
     ]
    }
   ],
   "source": [
    "with tf.device(\"GPU:1\"):\n",
    "    hist = vxm_model.fit(train_gen,\n",
    "                         steps_per_epoch = Train_num * 64,\n",
    "                         epochs=2000,\n",
    "                         callbacks=[checkpointer, \n",
    "                                    csv_logger,\n",
    "                                    early_stopping,\n",
    "                                    plot_learning_curves_epoch\n",
    "                                   ],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe331db4-8ae6-4b13-aeb4-10591fba4de8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "# 4. Inference Step & Image reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77dfe0-6467-491b-b57a-efd7b1fb42d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_df = pd.read_csv(os.path.join(save_model_path, r'log.csv'))\n",
    "plot_learning_curve(log_df)\n",
    "display.display(log_df.iloc[[log_df.val_loss.idxmin()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c17384-c779-415a-ad24-39f8930ffa6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_epoch = log_df.loss.idxmin()\n",
    "print(best_epoch)\n",
    "vxm_model.load_weights(glob.glob(os.path.join(save_model_path, \"weights_01577_-0.994.h5\"))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76743d18-c3d5-4ac7-9e95-bf3f5763999e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_subject_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924c6d7-d74a-476f-8a58-f70f520937de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "moving_patches , location_A = make_patches(V_moving[val_subject_num:val_subject_num+1],patch_size)\n",
    "fixed_patches  , location_A = make_patches(V_fixed[val_subject_num:val_subject_num+1] ,patch_size)\n",
    "                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc30230-8d32-463e-a1bb-91ed841d759e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    val_pred = vxm_model.predict([moving_patches,fixed_patches]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea9197-af70-47f6-ad4f-277690cb5e7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recon_image = np.zeros((512,512,192))\n",
    "for loc_idx in range(len(location_A)):\n",
    "    a_coor_A, b_coor_A = location_A[loc_idx][1] , location_A[loc_idx][2]  \n",
    "    recon_image[a_coor_A:a_coor_A+patch_size,\n",
    "                b_coor_A:b_coor_A+patch_size,...]= val_pred[0][loc_idx][...,0]\n",
    "    \n",
    "recon_image = np.swapaxes(recon_image[:512,:512,:],0,1)*10000\n",
    "# recon_image =recon_image[:512,:512,:]*10000\n",
    "\n",
    "print(recon_image.shape)\n",
    "print(recon_image.max())\n",
    "print(recon_image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949da2fe-0f37-4480-93e4-f484e1741c87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "slice_number = 170\n",
    "moving = np.swapaxes(V_moving[val_subject_num][...,slice_number],0,1)*10000\n",
    "fixed = np.swapaxes(V_fixed[val_subject_num][...,slice_number],0,1)*10000\n",
    "predict = recon_image[:,:,slice_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19cf11-64bf-4a3e-aecc-b498f032be60",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,40))\n",
    "plt.subplot(1, 3, 1).axis('off')       \n",
    "plt.imshow(moving,cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 2).axis('off')    \n",
    "plt.imshow(fixed ,cmap='gray')\n",
    "plt.subplot(1, 3, 3).axis('off')\n",
    "plt.imshow(predict ,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0e98f-c6f1-4dfc-9fa3-29ae75c554bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "fig , (ax1,ax2,ax3) =plt.subplots(1, 3,figsize=(30,30))\n",
    "\n",
    "\n",
    "z1_plot = ax1.imshow(moving,cmap='gray')\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "z2_plot = ax2.imshow(fixed ,cmap='gray')\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "z3_plot = ax3.imshow((norm(fixed) - norm(moving)),cmap='RdBu' ,vmin =- 0.5, vmax = 0.5 )\n",
    "ax3.axis(\"off\")\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(z3_plot, cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847541a6-210f-413f-86bc-dcfab71f8a09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "fig , (ax1,ax2,ax3) =plt.subplots(1, 3,figsize=(30,30))\n",
    "\n",
    "\n",
    "z1_plot = ax1.imshow(predict,cmap='gray')\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "z2_plot = ax2.imshow(fixed ,cmap='gray')\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "z3_plot = ax3.imshow((norm(fixed) - norm(predict)),cmap='RdBu' ,vmin =- 0.5, vmax = 0.5 )\n",
    "ax3.axis(\"off\")\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(z3_plot, cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919a2ed-b24b-48d8-b89f-c3375aa5a471",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "# 5. Prediction Data Save & Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9de9c1-a169-4938-8b15-e58bf6f883f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nii_input = nib.load(val_D_paths[val_subject_num])\n",
    "header = nii_input.header\n",
    "new_image = nib.Nifti1Image(moving_data[val_subject_num],nii_input.affine, header)\n",
    "nib.save(new_image,'moving_HCC_1765_D.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e9a8d-f57e-49df-b24e-e72f2e13e240",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nii_input = nib.load(val_P_paths[val_subject_num])\n",
    "header = nii_input.header\n",
    "new_image = nib.Nifti1Image(fixed_data[val_subject_num],nii_input.affine, header)\n",
    "nib.save(new_image,'fixed_HCC_1765_P.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11311d34-ac3b-404d-84ca-0b46daca2bc4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recon_image = np.zeros((512,512,192))\n",
    "for loc_idx in range(len(location_A)):\n",
    "    a_coor_A, b_coor_A = location_A[loc_idx][1] , location_A[loc_idx][2]  \n",
    "    recon_image[a_coor_A:a_coor_A+patch_size,\n",
    "                b_coor_A:b_coor_A+patch_size,...]= val_pred[0][loc_idx][...,0]\n",
    "    \n",
    "# recon_image = np.swapaxes(recon_image[:512,:512,:],0,1)*10000\n",
    "recon_image =recon_image[:512,:512,:]*10000\n",
    "\n",
    "print(recon_image.shape)\n",
    "print(recon_image.max())\n",
    "print(recon_image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83160e7-b973-45f9-a723-908bc6475afc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nii_input = nib.load(val_D_paths[val_subject_num])\n",
    "z_slice = nii_input.get_fdata()\n",
    "header = nii_input.header\n",
    "new_image = nib.Nifti1Image(recon_image,nii_input.affine, header)\n",
    "nib.save(new_image,'moved_HCC_1469_D.nii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3,8(vm2)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}